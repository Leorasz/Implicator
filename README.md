This is an intermediate testing phase of a research project I'm working on. The goal is to be able to perform "forensic analysis" where given limited facts you can imply more information from it.  

The dataset used was originally Wikipedia and then that was altered to only have the intro sections of individuals. All of these were then fed through an LLM to break each mini-biography down into individual facts which were then further cleaned and parsed. All of the facts are then embedded and each individual is stored as the indices of their facts.  

The "model" consists of two neural networks: an updater :: R^situation-dimension -> R^fact-dimension -> R^situation-dimension which given the current situation vector (starting from the zero vector) creates an update to it given the fact. Then there's the poller :: R^situation-dimension -> R^fact-dimension -> [0,1] which "polls" the situation for the fact and gives the "score" that the fact belongs to the situation. As previously mentioned, each individual is made up of facts. In training, for each fact the situation is updated with it, but then is polled against every other fact in the individual, including the ones not yet given. This "forced guessing" technique is the key to making implications and not letting the model stick to only what it's been given.

The embedding generation and generation of other useful files is embedding\_organizer.py, the implicator itself and training is in implicator.py, and to test it use implicator\_tester.py
